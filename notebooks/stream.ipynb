{"cells": [{"cell_type": "code", "execution_count": null, "id": "b5071420-e2b6-41c8-9662-ff2a3f4bbc2e", "metadata": {}, "outputs": [], "source": "import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row\nappName= \"hive_pyspark\"\nmaster= \"local\"\nimport matplotlib.pyplot as plt\nfrom textblob import TextBlob\nimport pyspark.sql.functions as F\nfrom pyspark.ml import Pipeline, Transformer\nfrom pyspark.ml.feature import Bucketizer\nfrom pyspark.sql import DataFrame\nfrom typing import Iterable\nimport pandas as pd\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport numpy as np\nfrom pyspark.sql.functions import udf,col, lower, to_date\nfrom pyspark.sql.types import FloatType\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\nfrom pyspark.mllib.tree import RandomForestModel, RandomForest\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.sql.functions import *"}, {"cell_type": "code", "execution_count": null, "id": "5047f5c0-78bd-476b-8bee-b478bb92fd24", "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder.appName(\"readfromscsv\").master(master).getOrCreate()"}, {"cell_type": "code", "execution_count": null, "id": "3b79ea4a-58a7-4a38-8bb4-a538115395a5", "metadata": {}, "outputs": [], "source": "df_posts_all = spark.read.csv(\"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/df_sentiment.csv\", header=True, inferSchema =True)\n\nappName= \"hive_pyspark\"\nmaster= \"local\"\nspark = SparkSession.builder.master(master).appName(appName).enableHiveSupport().getOrCreate()\n\n\ndf_stock = spark.read.csv(\"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/stream_data/stock/stock_file_1.csv\", header=True, inferSchema =True)\n\nposts_to_schema = df_posts_all.select(\"created_at\", \"sentiment\")\n\nstock_to_schema = df_stock\nschema_posts = posts_to_schema.schema\nschema_stock = stock_to_schema.schema"}, {"cell_type": "code", "execution_count": null, "id": "beb15a0c-2338-42e4-85df-38761c9904f4", "metadata": {}, "outputs": [], "source": "stock_data = spark.readStream.format(\"csv\").schema(schema_stock).option(\"header\", True).option(\"maxFilesPerTrigger\", 1)\\\n.load(\"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/stream_data/stock\")\n\nposts_data = spark.readStream.format(\"csv\").schema(schema_posts).option(\"header\", True).option(\"maxFilesPerTrigger\", 1)\\\n.load(\"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/stream_data/posts\")\n"}, {"cell_type": "code", "execution_count": null, "id": "b42da506-c960-4c41-ad07-94bdb06d0f27", "metadata": {}, "outputs": [], "source": "stock_data.isStreaming"}, {"cell_type": "code", "execution_count": null, "id": "89bc4fdc-8ec3-44a3-8925-a6074d133fb8", "metadata": {}, "outputs": [], "source": "class FeatureExtractor(Transformer):\n\n    def __init__(self):\n        super(FeatureExtractor, self).__init__()\n\n    def _transform(self, df: DataFrame) -> DataFrame:\n        df = df.select(mean(expr(\"CASE WHEN sentiment > 0.2 THEN sentiment \" +\n           \"ELSE NULL  END\")).alias(\"mean_positive\"), mean(expr(\"CASE WHEN sentiment < -0.2 THEN sentiment \" +\n           \"ELSE NULL  END\")).alias(\"mean_negative\"), mean(expr(\"CASE WHEN sentiment > -0.2 AND sentiment < 0.2  THEN sentiment \" +\n           \"ELSE NULL  END\")).alias(\"mean_neutral\"), \n                  count(expr(\"CASE WHEN sentiment > 0.2 THEN sentiment \" +\n           \"ELSE NULL END\")).alias(\"nr_positive\"), count(expr(\"CASE WHEN sentiment < -0.2 THEN sentiment \" +\n           \"ELSE NULL  END\")).alias(\"nr_negative\"), count(expr(\"CASE WHEN sentiment > -0.2 AND sentiment < 0.2  THEN sentiment \" +\n           \"ELSE NULL  END\")).alias(\"nr_neutral\"))\n        return df\n\n"}, {"cell_type": "markdown", "id": "5fa9361b-4cd3-470d-a1e0-93232b3faf17", "metadata": {}, "source": "## TWITTER"}, {"cell_type": "code", "execution_count": null, "id": "74079b7a-3afe-4667-8d16-dbf8966f8be3", "metadata": {"tags": []}, "outputs": [], "source": "feature_extractor = FeatureExtractor()\n\nvector_assembler = VectorAssembler(inputCols = [\"nr_negative\", \"nr_positive\", \"nr_neutral\", \"mean_negative\", \"mean_positive\", \"mean_neutral\"], outputCol = 'features')\n\nposts_model = RandomForestClassificationModel.load(\"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/ml_models/rf_posts_model\")\nmyStages = [feature_extractor, vector_assembler, posts_model]\npipeline = Pipeline(stages= myStages).fit(posts_data)\noutput = pipeline.transform(posts_data)\\\n.select(\"nr_negative\", \"nr_positive\", \"nr_neutral\", \"mean_negative\", \"mean_positive\", \"mean_neutral\", \"prediction\")\n\n\n#-----------PRINT PREDICTIONS-------------\nquery = output.writeStream.format(\"console\").outputMode(\"complete\").start()"}, {"cell_type": "markdown", "id": "d5f6bcec-c3b2-4f51-a06a-aab06dde19ef", "metadata": {}, "source": "## STOCK"}, {"cell_type": "code", "execution_count": null, "id": "1ff055d7-1fa7-45ee-83c2-5c342e413478", "metadata": {}, "outputs": [], "source": "class Pivot(Transformer):\n\n    def __init__(self):\n        super(Pivot, self).__init__()\n\n    def _transform(self, df: DataFrame) -> DataFrame:\n        \n        df = df.select('p', 'num')\n        condition = \"SELECT \"\n        for i in range(1,100):\n            condition += f'sum(CASE WHEN num = {i} THEN p ELSE NULL END), '\n        condition += f'sum(CASE WHEN num = 100 THEN p ELSE NULL END)'  \n        condition += \"FROM df\"\n\n        df.createOrReplaceTempView('df')\n        df = spark.sql(condition)\n    \n        newColumns = [f'c_{i}' for i in range(100)]\n        df = df.toDF(*newColumns)\n        return df\n"}, {"cell_type": "code", "execution_count": null, "id": "39e83887-13a1-40c9-9c91-b0a4e662ac9f", "metadata": {"tags": []}, "outputs": [], "source": "pivot = Pivot()\n\nvector_assembler = VectorAssembler(inputCols = [f'c_{i}' for i in range(100)], outputCol = 'features')\nsf = SelectFeatures()\nstock_model_RF = RandomForestClassificationModel.load(\"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/ml_models/rf_stock_model\")\nmyStages = [pivot, vector_assembler, stock_model_RF]\n\npipeline = Pipeline(stages= myStages).fit(stock_data)\noutput = pipeline.transform(stock_data).select(\"prediction\")\n\n#-----------PRINT PREDICTIONS-------------\nquery = output.writeStream.format(\"console\").outputMode(\"complete\").start()\n"}, {"cell_type": "code", "execution_count": null, "id": "4c68f9b0-51f9-4161-80e0-7587a5b0b1fd", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "da308e7f-245e-4176-a41b-ac3bfd02b5ec", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}