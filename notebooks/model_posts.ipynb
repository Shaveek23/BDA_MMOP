{"cells": [{"cell_type": "code", "execution_count": null, "id": "815f0d63-91f3-4444-9866-97a7ccaed63a", "metadata": {}, "outputs": [], "source": "import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row\n# appName= \"hive_pyspark\"\n# master= \"local\"\nimport matplotlib.pyplot as plt\nfrom textblob import TextBlob\n\nimport pandas as pd\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport numpy as np\nfrom pyspark.sql.functions import udf,col, lower\nfrom pyspark.sql.types import FloatType\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\nfrom pyspark.mllib.tree import RandomForestModel, RandomForest\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.classification import OneVsRest, OneVsRestModel\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\nfrom pyspark.ml.classification import OneVsRest, OneVsRestModel\nfrom pyspark.ml.classification import LinearSVC"}, {"cell_type": "code", "execution_count": null, "id": "38900400-3b6b-45ee-b827-d33040f9ff07", "metadata": {}, "outputs": [], "source": "basePath = 'hdfs://cluster-a0d6-m/user/mmop/posts/'\npaths = ['hdfs://cluster-a0d6-m/user/mmop/posts/*']\nparquetFile = spark.read.option(\"basePath\", basePath).parquet(*paths)\ndf = parquetFile.toPandas()\nstocks = spark.read.csv(\"hdfs://cluster-a0d6-m/user/mmop/twitter_input.csv\", header=True, inferSchema =True)"}, {"cell_type": "code", "execution_count": null, "id": "3c335817-6563-4f17-bb93-330773ff8257", "metadata": {}, "outputs": [], "source": "def calculate_sentiment(sentence):\n    blob_text = TextBlob(sentence)\n    sentiment = blob_text.sentiment.polarity\n    return sentiment\n\n \ndef apply_sentiment(df):\n    df[\"sentiment\"] = df.progress_apply(lambda x: calculate_sentiment(x[\"text\"]) , axis = 1)\n\n    df= df.drop_duplicates()\n    X = df[[\"id\", \"created_at\", \"sentiment\"]]\n    return X\n\nX = apply_sentiment(df)\nX.to_csv(\"df_sentiment.csv\", index = False)"}, {"cell_type": "code", "execution_count": null, "id": "48f30b54-3af8-40f0-b45a-7d5bd46527b8", "metadata": {}, "outputs": [], "source": "# df_sentiment = pd.read_csv(\"df_sentiment.csv\")"}, {"cell_type": "code", "execution_count": null, "id": "33725efc-4764-4349-95c1-30ce44ae57ac", "metadata": {}, "outputs": [], "source": "def features_extraction(df):\n    \n    nr_neg = len(df[df[\"sentiment\"] < -0.2])\n    nr_pos = len(df[df[\"sentiment\"] > 0.2])\n    nr_neutral = len(df[(df[\"sentiment\"] >= -0.2) & (df[\"sentiment\"] <= 0.2)])\n    mean_neg = np.mean(df[df[\"sentiment\"] < -0.2][\"sentiment\"])\n    mean_pos = np.mean(df[df[\"sentiment\"] > 0.2][\"sentiment\"])\n    mean_neutral = np.mean(df[(df[\"sentiment\"] >= -0.2) & (df[\"sentiment\"] <= 0.2)][\"sentiment\"])\n    res_dict = {\n        \"nr_neg\" : nr_neg,\n        \"nr_pos\" : nr_pos,\n        \"nr_neutral\" : nr_neutral, \n        \"mean_neg\" : mean_neg,\n        \"mean_pos\" : mean_pos,\n        \"mean_neutal\" : mean_neutral\n    }\n    return res_dict"}, {"cell_type": "code", "execution_count": null, "id": "deaac001-793d-4de2-9715-74cb942b3667", "metadata": {}, "outputs": [], "source": "def create_post_dataset(stock, X):\n    \n    X = X.drop_duplicates()\n    X = X[[\"id\", \"created_at\", \"sentiment\"]]\n    X = X.drop([1301566,1298190])\n    stock = stock.toPandas()\n    stock[\"start_timestamp\"] = pd.to_datetime(stock[\"start_timestamp\"])\n    stock[\"stop_timestamp\"] = pd.to_datetime(stock[\"stop_timestamp\"])\n    X[\"created_at\"] = pd.to_datetime(X[\"created_at\"])\n    \n    df_post = pd.DataFrame(columns = [\"nr_neg\", \"nr_pos\", \"nr_neutral\", \"mean_neg\", \"mean_pos\", \"mean_neutal\", \"start\", \"stop\", \"label\", \"index\"])\n    for i in tqdm(range(len(stock))):\n        start = stock.loc[i, \"start_timestamp\"]\n        stop = stock.loc[i, \"stop_timestamp\"]\n        label = stock.loc[i, \"label\"]\n        index = stock.loc[i, \"index\"]\n\n        X_sub = X[(X['created_at'] <= stop) & (X['created_at'] >= start)]\n        fe = features_extraction(X_sub)\n        fe[\"start\"] = start\n        fe[\"stop\"] = stop\n        fe[\"label\"] = label\n        fe[\"index\"] = index\n        df_post = df_post.append(fe, ignore_index = True)\n    return df_post\n"}, {"cell_type": "code", "execution_count": null, "id": "6a887fda-fa0e-4ab5-b497-c1b71cc4fbd0", "metadata": {}, "outputs": [], "source": "df_post_1 = create_post_dataset(stocks, df_sentiment).dropna()\n# spark.createDataFrame(df_post_1[[\"index\"]]).write.option(\"header\",\"true\").csv(\"hdfs://cluster-a0d6-m/user/mmop/indices_to_use.csv\")\ndf_posts_to_use = df_post_1[[\"nr_neg\", \"nr_pos\", \"nr_neutral\", \"mean_neg\", \"mean_pos\", \"mean_neutal\", \"label\", \"index\"]]\n# spark.createDataFrame(df_posts_to_use).write.option(\"header\",\"true\").csv(\"hdfs://cluster-a0d6-m/user/mmop/df_posts_to_use.csv\")\ndf_post_1_spark = spark.read.csv(\"hdfs://cluster-a0d6-m/user/mmop/df_posts_to_use.csv\", header=True, inferSchema =True) "}, {"cell_type": "code", "execution_count": null, "id": "4b953a00-da6c-4e56-9956-f28c88fa3b22", "metadata": {}, "outputs": [], "source": "vectorAssembler = VectorAssembler(inputCols = [\"nr_neg\", \"nr_pos\", \"nr_neutral\", \"mean_neg\", \"mean_pos\", \"mean_neutal\",\"label\", \"index\"], outputCol = 'features')\npost_final = vectorAssembler.transform(df_post_1_spark)\npost_final = post_final.select(['features', 'label'])\n"}, {"cell_type": "code", "execution_count": null, "id": "6ec7d1c4-a241-4882-8cbb-26d20375034a", "metadata": {}, "outputs": [], "source": "(trainingData, testData) = df_post_1_spark.randomSplit([0.7, 0.3], seed = 42)"}, {"cell_type": "code", "execution_count": null, "id": "0fff25e0-5054-43f5-8248-1a791af482b8", "metadata": {}, "outputs": [], "source": "# trainingData.select('index').write.option(\"header\",\"true\").csv(\"hdfs://cluster-a0d6-m/user/mmop/train_indices.csv\")\n# testData.select('index').write.option(\"header\",\"true\").csv(\"hdfs://cluster-a0d6-m/user/mmop/test_indices.csv\")\n"}, {"cell_type": "code", "execution_count": null, "id": "da789683-0ace-4c4c-b804-c3bb0a325bf9", "metadata": {}, "outputs": [], "source": "trainingIdx = spark.read.csv(\"hdfs://cluster-a0d6-m/user/mmop/train_indices.csv\", header=True, inferSchema =True) \ntestingIdx = spark.read.csv(\"hdfs://cluster-a0d6-m/user/mmop/test_indices.csv\", header=True, inferSchema =True) \ntrainingData = df_post_1_spark.join(trainingIdx, df_post_1_spark[\"index\"] == trainingIdx[\"index\"])\ntestingData = df_post_1_spark.join(testingIdx, df_post_1_spark[\"index\"] == testingIdx[\"index\"])"}, {"cell_type": "code", "execution_count": null, "id": "870b95ae-5384-4aad-bb2a-1a431cb7b262", "metadata": {}, "outputs": [], "source": "vectorAssembler = VectorAssembler(inputCols = [\"nr_neg\", \"nr_pos\", \"nr_neutral\", \"mean_neg\", \"mean_pos\", \"mean_neutal\"], outputCol = 'features')\npost_final_train = vectorAssembler.transform(trainingData)\npost_final_train = post_final_train.select(['features', 'label'])\n\nvectorAssembler = VectorAssembler(inputCols = [\"nr_neg\", \"nr_pos\", \"nr_neutral\", \"mean_neg\", \"mean_pos\", \"mean_neutal\"], outputCol = 'features')\npost_final_test = vectorAssembler.transform(testingData)\npost_final_test = post_final_test.select(['features', 'label'])\n"}, {"cell_type": "markdown", "id": "624f9d67-86bf-43df-be57-f214461207cf", "metadata": {}, "source": "ONE vs ALL"}, {"cell_type": "code", "execution_count": null, "id": "1ac32f19-194c-4996-b9ae-59f7f3a89623", "metadata": {}, "outputs": [], "source": "# instantiate the One Vs Rest Classifier.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\novr = OneVsRest(classifier=rf)\n\n# train the multiclass model.\novrModel = ovr.fit(post_final_train)\n\n# ovrModel.save(ml_models_path)\n\n# score the model on test data.\npredictions = ovrModel.transform(post_final_test)\n\n# obtain evaluator.\nevaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n\n# compute the classification error on test data.\naccuracy = evaluator.evaluate(predictions)\nprint(\"acc = %g\" % (accuracy))"}, {"cell_type": "code", "execution_count": null, "id": "e9118863-5228-4dd7-8dd4-ca66932a5af6", "metadata": {}, "outputs": [], "source": "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n\novr = OneVsRest(classifier=lsvc)\n\n# train the multiclass model.\novrModel = ovr.fit(post_final_train)\n\n# score the model on test data.\npredictions = ovrModel.transform(post_final_test)\n\n# obtain evaluator.\nevaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n\n# compute the classification error on test data.\naccuracy = evaluator.evaluate(predictions)\nprint(\"acc = %g\" % (accuracy))"}, {"cell_type": "code", "execution_count": null, "id": "fe92f19f-8908-424e-95eb-10812549091e", "metadata": {}, "outputs": [], "source": "# Train a GBT model.\ngbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n\novr = OneVsRest(classifier=gbt)\n\n# train the multiclass model.\novrModel = ovr.fit(post_final_train)\n\n# score the model on test data.\npredictions = ovrModel.transform(post_final_test)\n\n# obtain evaluator.\nevaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n\n# compute the classification error on test data.\naccuracy = evaluator.evaluate(predictions)\nprint(\"acc = %g\" % (accuracy))"}, {"cell_type": "code", "execution_count": null, "id": "695ab85e-de55-4a4d-8f44-9a03658ce050", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "ab58eb57-63d7-4032-ba80-dbd74581516c", "metadata": {}, "source": "### Random Forest"}, {"cell_type": "code", "execution_count": null, "id": "8491a1f1-d499-454e-b07b-3d7c94e26b73", "metadata": {}, "outputs": [], "source": "# (trainingData, testData) = post_final.randomSplit([0.7, 0.3], seed = 42)\n\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\nmodel = rf.fit(post_final_train)\n\npredictions = model.transform(post_final_test)\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\n\naccuracy = evaluator.evaluate(predictions)\n\nprint(accuracy)\n# predictions.select(col('probability')).show()"}, {"cell_type": "code", "execution_count": null, "id": "aadb1a6a-c052-4476-917e-a68c57e56deb", "metadata": {}, "outputs": [], "source": "ml_models_path = \"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/ml_models/rf__posts_model\""}, {"cell_type": "code", "execution_count": null, "id": "fd24649f-9027-4964-b7cb-48b112dd53a1", "metadata": {}, "outputs": [], "source": "model.save(ml_models_path)"}, {"cell_type": "code", "execution_count": null, "id": "1797f78a-502c-46c3-8863-a8c0de9ef929", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}