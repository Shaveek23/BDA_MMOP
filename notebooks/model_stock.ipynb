{"cells": [{"cell_type": "code", "execution_count": null, "id": "3ac88ba0-1c40-4e53-9598-b842129d5cca", "metadata": {}, "outputs": [], "source": "import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row\nappName= \"hive_pyspark\"\nmaster= \"local\"\nfrom pyspark.sql.functions import col, asc,desc, avg\nfrom tqdm import tqdm\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import StructType\nimport pandas as pd"}, {"cell_type": "code", "execution_count": null, "id": "3a675d62-cd3f-4b1b-b00a-2b318cfcb9bb", "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder.master(master).appName(appName).enableHiveSupport().getOrCreate()"}, {"cell_type": "code", "execution_count": null, "id": "8c48e23d-bb1c-4468-806c-468108209405", "metadata": {}, "outputs": [], "source": "spark.sql(\"USE mmop_tesla_project\")\ndf_stock = spark.sql(\"select * from stock\")\ndf = df_stock.groupby(\"t\").agg(avg(\"p\").alias(\"p\")).orderBy(col(\"t\").asc()) #.dropDuplicates([\"t\"])\ncount = df.count()"}, {"cell_type": "code", "execution_count": null, "id": "a71ce103-7d8e-48cd-ac51-966d125e7f9a", "metadata": {}, "outputs": [], "source": "print(count)"}, {"cell_type": "code", "execution_count": null, "id": "fca83213-8a5f-41f6-83e1-c81273509e2b", "metadata": {}, "outputs": [], "source": "# getting the list of Row objects\nrow_list = df.collect()\n\nwindow_size = 100\nnew_label = 20\nepsilon = 0.02\ni=0\n\noutput_df = pd.DataFrame()\n\npart = pd.DataFrame(row_list[i*window_size : (i+1)*window_size], columns=[\"t\", \"p\"])\npart_pivot = part[\"p\"].T#part.pivot(index=None, columns='t', values='p')\noutput_df = output_df.append(part_pivot, ignore_index=True)\noutput_df.loc[0, \"label\"] = 0\noutput_df.loc[0, \"start_timestamp\"] = part[\"t\"][0]\noutput_df.loc[0, \"stop_timestamp\"] = part[\"t\"][window_size-1]\n\nfor i in tqdm(range(1, int(count/window_size))):\n      \n    part = pd.DataFrame(row_list[i*window_size : (i+1)*window_size], columns=[\"t\", \"p\"])\n    part_pivot = part[\"p\"].T#part.pivot(index=None, columns='t', values='p')\n    output_df = output_df.append(part_pivot, ignore_index=True)\n    \n    mean = output_df.iloc[i-1, 0 : window_size-1].mean()\n    mean_label = output_df.iloc[i, 0 : new_label-1].mean()\n    if(abs(mean-mean_label)<epsilon):\n        output_df.loc[i-1, \"label\"] = 1 #no change\n    elif(mean>mean_label):\n        output_df.loc[i-1, \"label\"] = 0 #will decrease\n    elif(mean<mean_label):\n        output_df.loc[i-1, \"label\"] = 2 #will increase\n\n    output_df.loc[i, \"start_timestamp\"] = part[\"t\"][0]\n    output_df.loc[i, \"stop_timestamp\"] = part[\"t\"][window_size-1]\n\ni = int(count/window_size)\npart = pd.DataFrame(row_list[i*window_size : (i+1)*window_size], columns=[\"t\", \"p\"])\npart_pivot = part[\"p\"].T#part.pivot(index=None, columns='t', values='p')\n\nmean = output_df.iloc[i-1, 0 : window_size-1].mean()\nmean_label = part_pivot.mean()\nif(abs(mean-mean_label)<epsilon):\n    output_df.loc[i-1, \"label\"] = 1 #no change\nelif(mean>mean_label):\n    output_df.loc[i-1, \"label\"] = 0 #will decrease\nelif(mean<mean_label):\n    output_df.loc[i-1, \"label\"] = 2 #will increase"}, {"cell_type": "code", "execution_count": null, "id": "91153adf-f2c4-4e2b-aade-998ff95b1b0b", "metadata": {}, "outputs": [], "source": "output_df[\"id\"] = range(0, len(output_df))"}, {"cell_type": "markdown", "id": "cedd084f-7fbc-4f27-966d-74dbe220f251", "metadata": {}, "source": "## Save dataset"}, {"cell_type": "markdown", "id": "99ac6cb6-f9c1-4784-b43f-43232bf60e50", "metadata": {}, "source": "#### Save dataset to use it for posts"}, {"cell_type": "code", "execution_count": null, "id": "baa4f587-3e39-4a25-958f-ec3787b2fa08", "metadata": {}, "outputs": [], "source": "tmp = spark.createDataFrame(output_df[[\"start_timestamp\", \"stop_timestamp\", \"label\", \"index\"]])\ntmp.write.option(\"header\",\"true\").csv(\"hdfs://cluster-a0d6-m/user/mmop/twitter_input.csv\")"}, {"cell_type": "markdown", "id": "970450a9-5a73-4832-9ef6-30ccbfa394f6", "metadata": {}, "source": "### Save stock dataset for further use"}, {"cell_type": "code", "execution_count": null, "id": "f1e213c4-d6b2-4f6b-a096-7fba2ec3b4db", "metadata": {}, "outputs": [], "source": "spark.createDataFrame(output_df.drop([\"start_timestamp\", \"stop_timestamp\"], axis=1)).write.option(\"header\",\"true\").csv(\"hdfs://cluster-a0d6-m/user/mmop/stock_dataset.csv\")"}, {"cell_type": "markdown", "id": "cdb5fc44-d5bc-452b-a95e-f371f28a9d8e", "metadata": {}, "source": "### Prepare dataset"}, {"cell_type": "code", "execution_count": null, "id": "3b9136bc-6516-413e-a505-1c765318dfdf", "metadata": {}, "outputs": [], "source": "stock_dataset = spark.read.csv(\"hdfs://cluster-a0d6-m/user/mmop/stock_dataset.csv\", header=True, inferSchema =True)"}, {"cell_type": "code", "execution_count": null, "id": "ecff967e-49ff-4737-b62f-faeed27a804e", "metadata": {}, "outputs": [], "source": "trainingData_tmp = spark.read.csv(\"hdfs://cluster-a0d6-m/user/mmop/train_indices.csv\", header=True, inferSchema =True)\ntestData_tmp = spark.read.csv(\"hdfs://cluster-a0d6-m/user/mmop/test_indices.csv\", header=True, inferSchema =True)\n\ntrainingData = stock_dataset.join(trainingData_tmp, stock_dataset[\"id\"] == trainingData_tmp[\"index\"])\ntestData = stock_dataset.join(testData_tmp, stock_dataset[\"id\"] == testData_tmp[\"index\"])"}, {"cell_type": "markdown", "id": "ab08d23c-87b3-4bf9-9566-e8d0fcd75bda", "metadata": {}, "source": "# Train model"}, {"cell_type": "code", "execution_count": null, "id": "12aec5bf-2144-460c-97f1-4a9c881e630b", "metadata": {}, "outputs": [], "source": "from pyspark.ml import Pipeline\n\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\nfrom pyspark.ml.classification import OneVsRest, OneVsRestModel\nfrom pyspark.ml.classification import LinearSVC\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer, IndexToString"}, {"cell_type": "markdown", "id": "e721e496-6016-489d-b339-5f08f795cf31", "metadata": {}, "source": "### Parse dataset"}, {"cell_type": "code", "execution_count": null, "id": "155f3afd-8e75-4aad-affd-c60fc48192b6", "metadata": {}, "outputs": [], "source": "def parse_dataset(dataset):\n    # Load and parse the data file, converting it to a DataFrame.\n    columns = dataset.columns\n    columns.remove(\"index\")\n    columns.remove(\"label\")\n    columns.remove(\"id\")\n\n    vectorAssembler = VectorAssembler(inputCols = columns, outputCol = 'features')\n    data = vectorAssembler.transform(dataset)\n    return data.select(['features', 'label'])"}, {"cell_type": "code", "execution_count": null, "id": "c0e5302b-e3c6-40a1-9c71-325c0ea393b2", "metadata": {}, "outputs": [], "source": "trainingData = parse_dataset(trainingData)\ntestData = parse_dataset(testData)"}, {"cell_type": "code", "execution_count": null, "id": "b9342c0e-724a-4a84-865c-0609719abae3", "metadata": {}, "outputs": [], "source": "# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nlabelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(trainingData)"}, {"cell_type": "code", "execution_count": null, "id": "57123a99-f9c3-4f27-b01f-9b669eae1cea", "metadata": {"tags": []}, "outputs": [], "source": "# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nlabelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(trainingData)\n# Automatically identify categorical features, and index them.\n# Set maxCategories so features with > 4 distinct values are treated as continuous.\nfeatureIndexer =\\\n    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\").fit(trainingData)"}, {"cell_type": "markdown", "id": "9f2bf04c-cfc4-4645-ba37-cd5756f3d4a7", "metadata": {}, "source": "### RandomForest"}, {"cell_type": "code", "execution_count": null, "id": "0b02937b-3fa6-4f32-b00f-fb9aee9357c7", "metadata": {}, "outputs": [], "source": "ml_models_path = \"gs://dataproc-staging-europe-west4-375495060785-ncrgfyir/notebooks/jupyter/ml_models/rf_stock_model\""}, {"cell_type": "code", "execution_count": null, "id": "28f2d902-58f5-43d7-94bc-d496374be8e1", "metadata": {}, "outputs": [], "source": "# Train a RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n\n# Train model.  This also runs the indexers.\nmodel = rf.fit(trainingData)\n\nmodel.save(ml_models_path)\n\n# Make predictions.\npredictions = model.transform(testData)\n\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"f1 = %g\" % (accuracy))"}, {"cell_type": "code", "execution_count": null, "id": "67ad51db-b255-4fa8-98ea-ea0fdfd1f592", "metadata": {}, "outputs": [], "source": "rf2 = RandomForestClassificationModel.load(ml_models_path)"}, {"cell_type": "code", "execution_count": null, "id": "52cfbd4d-8aa8-479e-9629-fb77a7e8d7c0", "metadata": {}, "outputs": [], "source": "# Make predictions.\npredictions = rf2.transform(testData)\n\n# Select (prediction, true label) and compute test error\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"f1 = %g\" % (accuracy))"}, {"cell_type": "markdown", "id": "16299967-fa8e-4a7f-8119-840465055577", "metadata": {}, "source": "# One vs all"}, {"cell_type": "markdown", "id": "f26c5db5-7d4b-4ba9-bc97-5496477f62f0", "metadata": {}, "source": "### RandomForest"}, {"cell_type": "code", "execution_count": null, "id": "da35d3d1-fa6b-424c-9d79-535d981e7b10", "metadata": {}, "outputs": [], "source": "# instantiate the One Vs Rest Classifier.\novr = OneVsRest(classifier=rf)\n\n# train the multiclass model.\novrModel = ovr.fit(trainingData)\n\n# ovrModel.save(ml_models_path)\n\n# score the model on test data.\npredictions = ovrModel.transform(testData)\n\n# obtain evaluator.\nevaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n\n# compute the classification error on test data.\naccuracy = evaluator.evaluate(predictions)\nprint(\"f1 = %g\" % (accuracy))"}, {"cell_type": "markdown", "id": "06e5864b-1f97-43b6-994a-ca00ad3c0700", "metadata": {}, "source": "### LinearSVC"}, {"cell_type": "code", "execution_count": null, "id": "6be0baeb-1d31-4855-a826-97f95c17d875", "metadata": {}, "outputs": [], "source": "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n\novr = OneVsRest(classifier=lsvc)\n\n# train the multiclass model.\novrModel = ovr.fit(trainingData)\n\n# score the model on test data.\npredictions = ovrModel.transform(testData)\n\n# obtain evaluator.\nevaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n\n# compute the classification error on test data.\naccuracy = evaluator.evaluate(predictions)\nprint(\"f1 = %g\" % (accuracy))"}, {"cell_type": "markdown", "id": "21600b48-581d-43dd-90c8-f5314c68a740", "metadata": {}, "source": "### GradientBoosting"}, {"cell_type": "code", "execution_count": null, "id": "82a166d2-50e6-4a94-9514-ceef95e4e6bc", "metadata": {}, "outputs": [], "source": "# Train a GBT model.\ngbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n\novr = OneVsRest(classifier=gbt)\n\n# train the multiclass model.\novrModel = ovr.fit(trainingData)\n\n# score the model on test data.\npredictions = ovrModel.transform(testData)\n\n# obtain evaluator.\nevaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n\n# compute the classification error on test data.\naccuracy = evaluator.evaluate(predictions)\nprint(\"f1 = %g\" % (accuracy))"}, {"cell_type": "markdown", "id": "14abd296-95b0-41c2-b278-8e3b9f8924c3", "metadata": {}, "source": "## Sklearn test (not used in solution)"}, {"cell_type": "code", "execution_count": null, "id": "cc06f66a-3dd9-459a-9bf6-947b0217adfb", "metadata": {}, "outputs": [], "source": "from sklearn.ensemble import GradientBoostingClassifier"}, {"cell_type": "code", "execution_count": null, "id": "21f104fc-9a9f-4d5a-91b5-1a3b2c988735", "metadata": {}, "outputs": [], "source": "sklearn_data = output_df.drop([\"start_timestamp\", \"stop_timestamp\"], axis=1)"}, {"cell_type": "code", "execution_count": null, "id": "1278589f-dcf9-4b61-ac0c-b07ade31baec", "metadata": {}, "outputs": [], "source": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(sklearn_data.drop(\"label\",axis=1), sklearn_data[\"label\"], test_size=0.33, random_state=42)"}, {"cell_type": "code", "execution_count": null, "id": "121ed6d0-b7a6-47af-95e4-51f21fd32396", "metadata": {}, "outputs": [], "source": "clf = GradientBoostingClassifier().fit(X_train, y_train)\nclf.score(X_test, y_test)"}, {"cell_type": "code", "execution_count": null, "id": "4ebee50f-ba06-4008-817b-c83c3c260458", "metadata": {}, "outputs": [], "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score\n\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(X_train, y_train)\n\nprint(accuracy_score(y_test, clf.predict(X_test)))"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}